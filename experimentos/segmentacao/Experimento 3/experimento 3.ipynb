{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVVu2lXkcubl"
   },
   "source": [
    "### Install the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-eLWrn8CDjj4",
    "outputId": "0912bf4b-23c0-4c24-d057-c37092beb179"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SM_FRAMEWORK=tf.keras\n"
     ]
    }
   ],
   "source": [
    "#!pip install git+https://github.com/gabri14el/image-segmentation-keras\r\n",
    "%env SM_FRAMEWORK=tf.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-ZXJVRmc3BA"
   },
   "source": [
    "### Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5M_dfglnD2O4",
    "outputId": "f89907b6-c68e-4163-a59c-c0fba76d91cf"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\r\n",
    "import os\r\n",
    "save_path = r'.\\\\' ''\r\n",
    "experiment_description = 'experimento3'\r\n",
    "\r\n",
    "#diretorio onde est√° o dataset\r\n",
    "out = r'C:\\Users\\Gabriel\\Downloads\\Saida_'+experiment_description\r\n",
    "\r\n",
    "main_dir = r'C:\\Users\\Gabriel\\OneDrive - Universidade de Tras-os-Montes e Alto Douro\\UTAD\\2020-2021\\Pesquisa\\Dataset\\teste_masks_crop3'\r\n",
    "\r\n",
    "#subpastas que diferenciam imagem de mascaras\r\n",
    "image_dir = 'image'\r\n",
    "mask_dir = 'mask'\r\n",
    "\r\n",
    "# set the necessary directories\r\n",
    "trainimg_dir = os.path.join(main_dir, 'train', image_dir)\r\n",
    "trainmsk_dir = os.path.join(main_dir, 'train', mask_dir)\r\n",
    "valimg_dir = os.path.join(main_dir, 'validation', image_dir)\r\n",
    "valmsk_dir = os.path.join(main_dir, 'validation', mask_dir)\r\n",
    "testimg_dir = os.path.join(main_dir, 'test', image_dir)\r\n",
    "testmsk_dir = os.path.join(main_dir, 'test', mask_dir)\r\n",
    "\r\n",
    "batch = 6\r\n",
    "LR = 0.0001\r\n",
    "EPOCHS = 50\r\n",
    "\r\n",
    "train_steps = len(os.listdir(trainimg_dir))/batch\r\n",
    "val_steps = len(os.listdir(valimg_dir))/batch\r\n",
    "\r\n",
    "target_size = (320, 320)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpVgw4szckFI"
   },
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-l3Lzy5nDqCw",
    "outputId": "17885a14-de81-4c9a-86d9-55255d32437a"
   },
   "outputs": [],
   "source": [
    "from keras_segmentation.models.segnet import resnet50_segnet\r\n",
    "\r\n",
    "model = resnet50_segnet(n_classes=2 ,  input_height=target_size[0], input_width=target_size[1], encoder_level=4, n_up=5)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whqtlciFkab3"
   },
   "source": [
    "##Define callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QemGPtFQkcwj"
   },
   "outputs": [],
   "source": [
    "#os.makedirs(save_path, exist_ok = True)\r\n",
    "\r\n",
    "path_weight = os.path.join(save_path, experiment_description+'-weights.h5')\r\n",
    "path_model = os.path.join(save_path, experiment_description+'-model')\r\n",
    "\r\n",
    "model_checkpoint_weights_callback = tf.keras.callbacks.ModelCheckpoint(\r\n",
    "    filepath=path_weight,\r\n",
    "    save_weights_only=True,\r\n",
    "    monitor='val_accuracy',\r\n",
    "    mode='max',\r\n",
    "    save_best_only=True)\r\n",
    "\r\n",
    "model_checkpoint_model_callback = tf.keras.callbacks.ModelCheckpoint(\r\n",
    "    filepath=path_model,\r\n",
    "    save_weights_only=False,\r\n",
    "    monitor='val_accuracy',\r\n",
    "    mode='max',\r\n",
    "    save_best_only=True)\r\n",
    "\r\n",
    "reduce_on_plateau = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_f1_m', factor=0.95, patience=2, verbose=1, mode='max', cooldown=1, min_lr=0.000001),\r\n",
    "\r\n",
    "callbacks = [model_checkpoint_weights_callback, model_checkpoint_model_callback, reduce_on_plateau]\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qGd_TDGKcdL7"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jXKtRFd9EC0K",
    "outputId": "5caac0ac-1310-4d1e-9cc3-3b5e85531b84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 320, 320, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 326, 326, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 160, 160, 64) 9472        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 160, 160, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 160, 160, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 79, 79, 64)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 79, 79, 64)   4160        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 79, 79, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 79, 79, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 79, 79, 64)   36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 79, 79, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 79, 79, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 79, 79, 256)  16640       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 79, 79, 256)  16640       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 79, 79, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 79, 79, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 79, 79, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 79, 79, 256)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 79, 79, 64)   16448       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 79, 79, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 79, 79, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 79, 79, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 79, 79, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 79, 79, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 79, 79, 256)  16640       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 79, 79, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 79, 79, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 79, 79, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 79, 79, 64)   16448       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 79, 79, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 79, 79, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 79, 79, 64)   36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 79, 79, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 79, 79, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 79, 79, 256)  16640       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 79, 79, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 79, 79, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 79, 79, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 40, 40, 128)  32896       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 40, 40, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 40, 40, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 40, 40, 128)  147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 40, 40, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 40, 40, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 40, 40, 512)  66048       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 40, 40, 512)  131584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 40, 40, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 40, 40, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 40, 40, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 40, 40, 512)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 40, 40, 128)  65664       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 40, 40, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 40, 40, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 40, 40, 128)  147584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 40, 40, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 40, 40, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 40, 40, 512)  66048       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 40, 40, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 40, 40, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 40, 40, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 40, 40, 128)  65664       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 40, 40, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 40, 40, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 40, 40, 128)  147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 40, 40, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 40, 40, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 40, 40, 512)  66048       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 40, 40, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 40, 40, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 40, 40, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 40, 40, 128)  65664       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 40, 40, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 40, 40, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 40, 40, 128)  147584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 40, 40, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 40, 40, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 40, 40, 512)  66048       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 40, 40, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 40, 40, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 40, 40, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 20, 20, 256)  131328      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 20, 20, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 20, 20, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 20, 20, 256)  590080      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 20, 20, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 20, 20, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 20, 20, 1024) 263168      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 20, 20, 1024) 525312      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 20, 20, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 20, 20, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 20, 20, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 20, 20, 1024) 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 20, 20, 256)  262400      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 20, 20, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 20, 20, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 20, 20, 256)  590080      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 20, 20, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 20, 20, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 20, 20, 1024) 263168      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 20, 20, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 20, 20, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 20, 20, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 20, 20, 256)  262400      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 20, 20, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 20, 20, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 20, 20, 256)  590080      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 20, 20, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 20, 20, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 20, 20, 1024) 263168      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 20, 20, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 20, 20, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 20, 20, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 20, 20, 256)  262400      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 20, 20, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 20, 20, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 20, 20, 256)  590080      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 20, 20, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 20, 20, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 20, 20, 1024) 263168      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 20, 20, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 20, 20, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 20, 20, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 20, 20, 256)  262400      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 20, 20, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 20, 20, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 20, 20, 256)  590080      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 20, 20, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 20, 20, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 20, 20, 1024) 263168      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 20, 20, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 20, 20, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 20, 20, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 20, 20, 256)  262400      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 20, 20, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 20, 20, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 20, 20, 256)  590080      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 20, 20, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 20, 20, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 20, 20, 1024) 263168      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 20, 20, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 20, 20, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 20, 20, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 10, 10, 512)  524800      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 10, 10, 512)  2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 10, 10, 512)  0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 10, 10, 512)  2359808     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 10, 10, 512)  2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 10, 10, 512)  0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 10, 10, 2048) 1050624     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 10, 10, 2048) 2099200     activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 10, 10, 2048) 8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 10, 10, 2048) 8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 10, 10, 2048) 0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 10, 10, 2048) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 10, 10, 512)  1049088     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 10, 10, 512)  2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 10, 10, 512)  0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 10, 10, 512)  2359808     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 10, 10, 512)  2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 10, 10, 512)  0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 10, 10, 2048) 1050624     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 10, 10, 2048) 8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 10, 10, 2048) 0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 10, 10, 2048) 0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 10, 10, 512)  1049088     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 10, 10, 512)  2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 10, 10, 512)  0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 10, 10, 512)  2359808     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 10, 10, 512)  2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 10, 10, 512)  0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 10, 10, 2048) 1050624     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 10, 10, 2048) 8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 10, 10, 2048) 0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 10, 10, 2048) 0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 12, 12, 2048) 0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 10, 10, 512)  9437696     zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 10, 10, 512)  2048        conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 20, 20, 512)  0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 22, 22, 512)  0           up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 20, 20, 256)  1179904     zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 20, 20, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 40, 40, 256)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 42, 42, 256)  0           up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 40, 40, 128)  295040      zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 40, 40, 128)  512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 80, 80, 128)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 82, 82, 128)  0           up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 80, 80, 128)  147584      zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 80, 80, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 160, 160, 128 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 162, 162, 128 0           up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 160, 160, 128 147584      zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 160, 160, 128 512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 320, 320, 128 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, 322, 322, 128 0           up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "seg_feats (Conv2D)              (None, 320, 320, 64) 73792       zero_padding2d_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 320, 320, 64) 256         seg_feats[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 320, 320, 2)  1154        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 102400, 2)    0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 102400, 2)    0           reshape[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 34,875,330\n",
      "Trainable params: 11,285,186\n",
      "Non-trainable params: 23,590,144\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "883/883 [==============================] - 483s 532ms/step - loss: 0.2497 - accuracy: 0.8575 - mean_io_u: 0.2547 - f1_m: 0.8575 - val_loss: 0.1277 - val_accuracy: 0.9226 - val_mean_io_u: 0.2617 - val_f1_m: 0.9226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\experimento3-model\\assets\n",
      "Epoch 2/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.1051 - accuracy: 0.9356 - mean_io_u: 0.2507 - f1_m: 0.9356 - val_loss: 0.1009 - val_accuracy: 0.9361 - val_mean_io_u: 0.2581 - val_f1_m: 0.9361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\experimento3-model\\assets\n",
      "Epoch 3/50\n",
      "883/883 [==============================] - 468s 530ms/step - loss: 0.0887 - accuracy: 0.9428 - mean_io_u: 0.2514 - f1_m: 0.9428 - val_loss: 0.0972 - val_accuracy: 0.9388 - val_mean_io_u: 0.2745 - val_f1_m: 0.9388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\experimento3-model\\assets\n",
      "Epoch 4/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0828 - accuracy: 0.9466 - mean_io_u: 0.2536 - f1_m: 0.9466 - val_loss: 0.0966 - val_accuracy: 0.9393 - val_mean_io_u: 0.2911 - val_f1_m: 0.9393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\experimento3-model\\assets\n",
      "Epoch 5/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0753 - accuracy: 0.9519 - mean_io_u: 0.2586 - f1_m: 0.9519 - val_loss: 0.1054 - val_accuracy: 0.9355 - val_mean_io_u: 0.3139 - val_f1_m: 0.9355\n",
      "Epoch 6/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0694 - accuracy: 0.9559 - mean_io_u: 0.2660 - f1_m: 0.9559 - val_loss: 0.1117 - val_accuracy: 0.9318 - val_mean_io_u: 0.3093 - val_f1_m: 0.9318\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 9.499999760009814e-05.\n",
      "Epoch 7/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0657 - accuracy: 0.9582 - mean_io_u: 0.2744 - f1_m: 0.9582 - val_loss: 0.0959 - val_accuracy: 0.9393 - val_mean_io_u: 0.3047 - val_f1_m: 0.9393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\experimento3-model\\assets\n",
      "Epoch 8/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0612 - accuracy: 0.9613 - mean_io_u: 0.2844 - f1_m: 0.9613 - val_loss: 0.1119 - val_accuracy: 0.9311 - val_mean_io_u: 0.3162 - val_f1_m: 0.9311\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 9.02499959920533e-05.\n",
      "Epoch 9/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0568 - accuracy: 0.9642 - mean_io_u: 0.2969 - f1_m: 0.9642 - val_loss: 0.1242 - val_accuracy: 0.9250 - val_mean_io_u: 0.3321 - val_f1_m: 0.9250\n",
      "Epoch 10/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0547 - accuracy: 0.9655 - mean_io_u: 0.3097 - f1_m: 0.9655 - val_loss: 0.1024 - val_accuracy: 0.9379 - val_mean_io_u: 0.3581 - val_f1_m: 0.9379\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.573749619245064e-05.\n",
      "Epoch 11/50\n",
      "883/883 [==============================] - 466s 528ms/step - loss: 0.0522 - accuracy: 0.9671 - mean_io_u: 0.3219 - f1_m: 0.9671 - val_loss: 0.0999 - val_accuracy: 0.9373 - val_mean_io_u: 0.3248 - val_f1_m: 0.9373\n",
      "Epoch 12/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0496 - accuracy: 0.9688 - mean_io_u: 0.3339 - f1_m: 0.9688 - val_loss: 0.1093 - val_accuracy: 0.9332 - val_mean_io_u: 0.3297 - val_f1_m: 0.9332\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 8.145062311086804e-05.\n",
      "Epoch 13/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0497 - accuracy: 0.9685 - mean_io_u: 0.3464 - f1_m: 0.9685 - val_loss: 0.1219 - val_accuracy: 0.9272 - val_mean_io_u: 0.3496 - val_f1_m: 0.9272\n",
      "Epoch 14/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0482 - accuracy: 0.9695 - mean_io_u: 0.3558 - f1_m: 0.9695 - val_loss: 0.1104 - val_accuracy: 0.9349 - val_mean_io_u: 0.4187 - val_f1_m: 0.9349\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 7.737808919046074e-05.\n",
      "Epoch 15/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0467 - accuracy: 0.9705 - mean_io_u: 0.3635 - f1_m: 0.9705 - val_loss: 0.1225 - val_accuracy: 0.9260 - val_mean_io_u: 0.3605 - val_f1_m: 0.9260\n",
      "Epoch 16/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0449 - accuracy: 0.9718 - mean_io_u: 0.3741 - f1_m: 0.9718 - val_loss: 0.1180 - val_accuracy: 0.9255 - val_mean_io_u: 0.3171 - val_f1_m: 0.9255\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 7.350918749580159e-05.\n",
      "Epoch 17/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0435 - accuracy: 0.9726 - mean_io_u: 0.3823 - f1_m: 0.9726 - val_loss: 0.1336 - val_accuracy: 0.9240 - val_mean_io_u: 0.4438 - val_f1_m: 0.9240\n",
      "Epoch 18/50\n",
      "883/883 [==============================] - 465s 527ms/step - loss: 0.0420 - accuracy: 0.9736 - mean_io_u: 0.3902 - f1_m: 0.9736 - val_loss: 0.1199 - val_accuracy: 0.9295 - val_mean_io_u: 0.4136 - val_f1_m: 0.9295\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 6.983372950344346e-05.\n",
      "Epoch 19/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0408 - accuracy: 0.9744 - mean_io_u: 0.4014 - f1_m: 0.9744 - val_loss: 0.1106 - val_accuracy: 0.9355 - val_mean_io_u: 0.4802 - val_f1_m: 0.9355\n",
      "Epoch 20/50\n",
      "883/883 [==============================] - 466s 528ms/step - loss: 0.0397 - accuracy: 0.9750 - mean_io_u: 0.4095 - f1_m: 0.9750 - val_loss: 0.1092 - val_accuracy: 0.9380 - val_mean_io_u: 0.5219 - val_f1_m: 0.9380\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.634204510191921e-05.\n",
      "Epoch 21/50\n",
      "883/883 [==============================] - 466s 528ms/step - loss: 0.0385 - accuracy: 0.9759 - mean_io_u: 0.4174 - f1_m: 0.9759 - val_loss: 0.1216 - val_accuracy: 0.9325 - val_mean_io_u: 0.5359 - val_f1_m: 0.9325\n",
      "Epoch 22/50\n",
      "883/883 [==============================] - 466s 528ms/step - loss: 0.0376 - accuracy: 0.9764 - mean_io_u: 0.4275 - f1_m: 0.9764 - val_loss: 0.1128 - val_accuracy: 0.9371 - val_mean_io_u: 0.5378 - val_f1_m: 0.9371\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 6.302494111878331e-05.\n",
      "Epoch 23/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0373 - accuracy: 0.9766 - mean_io_u: 0.4372 - f1_m: 0.9766 - val_loss: 0.1136 - val_accuracy: 0.9359 - val_mean_io_u: 0.5090 - val_f1_m: 0.9359\n",
      "Epoch 24/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0365 - accuracy: 0.9771 - mean_io_u: 0.4441 - f1_m: 0.9771 - val_loss: 0.1175 - val_accuracy: 0.9315 - val_mean_io_u: 0.4340 - val_f1_m: 0.9315\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 5.9873694408452134e-05.\n",
      "Epoch 25/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0360 - accuracy: 0.9773 - mean_io_u: 0.4519 - f1_m: 0.9773 - val_loss: 0.1210 - val_accuracy: 0.9282 - val_mean_io_u: 0.4313 - val_f1_m: 0.9282\n",
      "Epoch 26/50\n",
      "883/883 [==============================] - 465s 527ms/step - loss: 0.0348 - accuracy: 0.9782 - mean_io_u: 0.4595 - f1_m: 0.9782 - val_loss: 0.1193 - val_accuracy: 0.9300 - val_mean_io_u: 0.4489 - val_f1_m: 0.9300\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 5.68800103792455e-05.\n",
      "Epoch 27/50\n",
      "883/883 [==============================] - 465s 527ms/step - loss: 0.0346 - accuracy: 0.9783 - mean_io_u: 0.4647 - f1_m: 0.9783 - val_loss: 0.1509 - val_accuracy: 0.9120 - val_mean_io_u: 0.4136 - val_f1_m: 0.9120\n",
      "Epoch 28/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0338 - accuracy: 0.9788 - mean_io_u: 0.4712 - f1_m: 0.9788 - val_loss: 0.1345 - val_accuracy: 0.9200 - val_mean_io_u: 0.4173 - val_f1_m: 0.9200\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 5.4036009169067255e-05.\n",
      "Epoch 29/50\n",
      "883/883 [==============================] - 465s 526ms/step - loss: 0.0328 - accuracy: 0.9795 - mean_io_u: 0.4780 - f1_m: 0.9795 - val_loss: 0.1263 - val_accuracy: 0.9249 - val_mean_io_u: 0.4303 - val_f1_m: 0.9249\n",
      "Epoch 30/50\n",
      "883/883 [==============================] - 465s 526ms/step - loss: 0.0315 - accuracy: 0.9804 - mean_io_u: 0.4835 - f1_m: 0.9804 - val_loss: 0.1608 - val_accuracy: 0.9080 - val_mean_io_u: 0.4427 - val_f1_m: 0.9080\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 5.133420836500591e-05.\n",
      "Epoch 31/50\n",
      "883/883 [==============================] - 464s 526ms/step - loss: 0.0315 - accuracy: 0.9803 - mean_io_u: 0.4913 - f1_m: 0.9803 - val_loss: 0.1315 - val_accuracy: 0.9257 - val_mean_io_u: 0.4951 - val_f1_m: 0.9257\n",
      "Epoch 32/50\n",
      "883/883 [==============================] - 465s 527ms/step - loss: 0.0304 - accuracy: 0.9811 - mean_io_u: 0.4982 - f1_m: 0.9811 - val_loss: 0.1222 - val_accuracy: 0.9295 - val_mean_io_u: 0.4828 - val_f1_m: 0.9295\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 4.876749881077558e-05.\n",
      "Epoch 33/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0295 - accuracy: 0.9816 - mean_io_u: 0.5029 - f1_m: 0.9816 - val_loss: 0.1307 - val_accuracy: 0.9244 - val_mean_io_u: 0.4633 - val_f1_m: 0.9244\n",
      "Epoch 34/50\n",
      "883/883 [==============================] - 465s 526ms/step - loss: 0.0294 - accuracy: 0.9817 - mean_io_u: 0.5098 - f1_m: 0.9817 - val_loss: 0.1240 - val_accuracy: 0.9303 - val_mean_io_u: 0.5229 - val_f1_m: 0.9303\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 4.63291238702368e-05.\n",
      "Epoch 35/50\n",
      "883/883 [==============================] - 465s 526ms/step - loss: 0.0283 - accuracy: 0.9824 - mean_io_u: 0.5166 - f1_m: 0.9824 - val_loss: 0.1235 - val_accuracy: 0.9312 - val_mean_io_u: 0.5323 - val_f1_m: 0.9312\n",
      "Epoch 36/50\n",
      "883/883 [==============================] - 465s 527ms/step - loss: 0.0277 - accuracy: 0.9828 - mean_io_u: 0.5214 - f1_m: 0.9828 - val_loss: 0.1243 - val_accuracy: 0.9313 - val_mean_io_u: 0.5434 - val_f1_m: 0.9313\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 4.4012669059156905e-05.\n",
      "Epoch 37/50\n",
      "883/883 [==============================] - 465s 527ms/step - loss: 0.0271 - accuracy: 0.9832 - mean_io_u: 0.5290 - f1_m: 0.9832 - val_loss: 0.1363 - val_accuracy: 0.9244 - val_mean_io_u: 0.5306 - val_f1_m: 0.9244\n",
      "Epoch 38/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0268 - accuracy: 0.9834 - mean_io_u: 0.5356 - f1_m: 0.9834 - val_loss: 0.1247 - val_accuracy: 0.9306 - val_mean_io_u: 0.5258 - val_f1_m: 0.9306\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 4.181203439657111e-05.\n",
      "Epoch 39/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0265 - accuracy: 0.9835 - mean_io_u: 0.5397 - f1_m: 0.9835 - val_loss: 0.1258 - val_accuracy: 0.9308 - val_mean_io_u: 0.5530 - val_f1_m: 0.9308\n",
      "Epoch 40/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0260 - accuracy: 0.9839 - mean_io_u: 0.5467 - f1_m: 0.9839 - val_loss: 0.1269 - val_accuracy: 0.9290 - val_mean_io_u: 0.5318 - val_f1_m: 0.9290\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 3.9721430948702614e-05.\n",
      "Epoch 41/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0258 - accuracy: 0.9840 - mean_io_u: 0.5518 - f1_m: 0.9840 - val_loss: 0.1267 - val_accuracy: 0.9302 - val_mean_io_u: 0.5448 - val_f1_m: 0.9302\n",
      "Epoch 42/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0251 - accuracy: 0.9844 - mean_io_u: 0.5559 - f1_m: 0.9844 - val_loss: 0.1271 - val_accuracy: 0.9292 - val_mean_io_u: 0.5334 - val_f1_m: 0.9292\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 3.773536009248346e-05.\n",
      "Epoch 43/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0249 - accuracy: 0.9845 - mean_io_u: 0.5613 - f1_m: 0.9845 - val_loss: 0.1314 - val_accuracy: 0.9269 - val_mean_io_u: 0.5317 - val_f1_m: 0.9269\n",
      "Epoch 44/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0242 - accuracy: 0.9850 - mean_io_u: 0.5657 - f1_m: 0.9850 - val_loss: 0.1322 - val_accuracy: 0.9268 - val_mean_io_u: 0.5393 - val_f1_m: 0.9268\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 3.584859277907526e-05.\n",
      "Epoch 45/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0240 - accuracy: 0.9851 - mean_io_u: 0.5704 - f1_m: 0.9851 - val_loss: 0.1525 - val_accuracy: 0.9164 - val_mean_io_u: 0.5228 - val_f1_m: 0.9164\n",
      "Epoch 46/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0235 - accuracy: 0.9854 - mean_io_u: 0.5749 - f1_m: 0.9854 - val_loss: 0.1454 - val_accuracy: 0.9196 - val_mean_io_u: 0.5249 - val_f1_m: 0.9196\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 3.4056162621709515e-05.\n",
      "Epoch 47/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0234 - accuracy: 0.9855 - mean_io_u: 0.5801 - f1_m: 0.9855 - val_loss: 0.1379 - val_accuracy: 0.9212 - val_mean_io_u: 0.4933 - val_f1_m: 0.9212\n",
      "Epoch 48/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0231 - accuracy: 0.9857 - mean_io_u: 0.5840 - f1_m: 0.9857 - val_loss: 0.1807 - val_accuracy: 0.9025 - val_mean_io_u: 0.5085 - val_f1_m: 0.9025\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 3.2353355527448004e-05.\n",
      "Epoch 49/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0228 - accuracy: 0.9859 - mean_io_u: 0.5878 - f1_m: 0.9859 - val_loss: 0.1583 - val_accuracy: 0.9159 - val_mean_io_u: 0.5651 - val_f1_m: 0.9159\n",
      "Epoch 50/50\n",
      "883/883 [==============================] - 466s 527ms/step - loss: 0.0223 - accuracy: 0.9862 - mean_io_u: 0.5929 - f1_m: 0.9862 - val_loss: 0.1412 - val_accuracy: 0.9228 - val_mean_io_u: 0.5482 - val_f1_m: 0.9228\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 3.0735688960703554e-05.\n",
      "Epoch 1/50\n",
      "883/883 [==============================] - 687s 764ms/step - loss: 0.1730 - accuracy: 0.9051 - mean_io_u_1: 0.5602 - f1_m: 0.9051 - val_loss: 0.1350 - val_accuracy: 0.9248 - val_mean_io_u_1: 0.5732 - val_f1_m: 0.9248\n",
      "Epoch 2/50\n",
      "883/883 [==============================] - 673s 762ms/step - loss: 0.1269 - accuracy: 0.9266 - mean_io_u_1: 0.5638 - f1_m: 0.9266 - val_loss: 0.1242 - val_accuracy: 0.9291 - val_mean_io_u_1: 0.5656 - val_f1_m: 0.9291\n",
      "Epoch 3/50\n",
      "883/883 [==============================] - 670s 758ms/step - loss: 0.1118 - accuracy: 0.9341 - mean_io_u_1: 0.5614 - f1_m: 0.9341 - val_loss: 0.1182 - val_accuracy: 0.9315 - val_mean_io_u_1: 0.5606 - val_f1_m: 0.9315\n",
      "Epoch 4/50\n",
      "883/883 [==============================] - 671s 760ms/step - loss: 0.0940 - accuracy: 0.9440 - mean_io_u_1: 0.5587 - f1_m: 0.9440 - val_loss: 0.1156 - val_accuracy: 0.9322 - val_mean_io_u_1: 0.5557 - val_f1_m: 0.9322\n",
      "Epoch 5/50\n",
      "883/883 [==============================] - 670s 758ms/step - loss: 0.0881 - accuracy: 0.9468 - mean_io_u_1: 0.5551 - f1_m: 0.9468 - val_loss: 0.1130 - val_accuracy: 0.9331 - val_mean_io_u_1: 0.5518 - val_f1_m: 0.9331\n",
      "Epoch 6/50\n",
      "883/883 [==============================] - 670s 759ms/step - loss: 0.0818 - accuracy: 0.9502 - mean_io_u_1: 0.5526 - f1_m: 0.9502 - val_loss: 0.1109 - val_accuracy: 0.9339 - val_mean_io_u_1: 0.5490 - val_f1_m: 0.9339\n",
      "Epoch 7/50\n",
      "883/883 [==============================] - 669s 757ms/step - loss: 0.0717 - accuracy: 0.9562 - mean_io_u_1: 0.5518 - f1_m: 0.9562 - val_loss: 0.1102 - val_accuracy: 0.9339 - val_mean_io_u_1: 0.5454 - val_f1_m: 0.9339\n",
      "Epoch 8/50\n",
      "883/883 [==============================] - 672s 761ms/step - loss: 0.0681 - accuracy: 0.9581 - mean_io_u_1: 0.5501 - f1_m: 0.9581 - val_loss: 0.1092 - val_accuracy: 0.9344 - val_mean_io_u_1: 0.5447 - val_f1_m: 0.9344\n",
      "Epoch 9/50\n",
      "883/883 [==============================] - 674s 762ms/step - loss: 0.0640 - accuracy: 0.9605 - mean_io_u_1: 0.5492 - f1_m: 0.9605 - val_loss: 0.1085 - val_accuracy: 0.9347 - val_mean_io_u_1: 0.5427 - val_f1_m: 0.9347\n",
      "Epoch 10/50\n",
      "883/883 [==============================] - 675s 763ms/step - loss: 0.0575 - accuracy: 0.9644 - mean_io_u_1: 0.5498 - f1_m: 0.9644 - val_loss: 0.1085 - val_accuracy: 0.9346 - val_mean_io_u_1: 0.5416 - val_f1_m: 0.9346\n",
      "Epoch 11/50\n",
      "883/883 [==============================] - 672s 761ms/step - loss: 0.0548 - accuracy: 0.9660 - mean_io_u_1: 0.5495 - f1_m: 0.9660 - val_loss: 0.1084 - val_accuracy: 0.9347 - val_mean_io_u_1: 0.5416 - val_f1_m: 0.9347\n",
      "Epoch 12/50\n",
      "883/883 [==============================] - 673s 761ms/step - loss: 0.0517 - accuracy: 0.9679 - mean_io_u_1: 0.5495 - f1_m: 0.9679 - val_loss: 0.1081 - val_accuracy: 0.9348 - val_mean_io_u_1: 0.5410 - val_f1_m: 0.9348\n",
      "Epoch 13/50\n",
      "883/883 [==============================] - 673s 762ms/step - loss: 0.0473 - accuracy: 0.9705 - mean_io_u_1: 0.5508 - f1_m: 0.9705 - val_loss: 0.1083 - val_accuracy: 0.9347 - val_mean_io_u_1: 0.5400 - val_f1_m: 0.9347\n",
      "Epoch 14/50\n",
      "883/883 [==============================] - 674s 763ms/step - loss: 0.0453 - accuracy: 0.9718 - mean_io_u_1: 0.5511 - f1_m: 0.9718 - val_loss: 0.1085 - val_accuracy: 0.9347 - val_mean_io_u_1: 0.5401 - val_f1_m: 0.9347\n",
      "Epoch 15/50\n",
      "883/883 [==============================] - 674s 763ms/step - loss: 0.0428 - accuracy: 0.9732 - mean_io_u_1: 0.5521 - f1_m: 0.9732 - val_loss: 0.1086 - val_accuracy: 0.9348 - val_mean_io_u_1: 0.5412 - val_f1_m: 0.9348\n",
      "Epoch 16/50\n",
      "883/883 [==============================] - 674s 763ms/step - loss: 0.0397 - accuracy: 0.9751 - mean_io_u_1: 0.5539 - f1_m: 0.9751 - val_loss: 0.1086 - val_accuracy: 0.9347 - val_mean_io_u_1: 0.5402 - val_f1_m: 0.9347\n",
      "Epoch 17/50\n",
      "883/883 [==============================] - 674s 763ms/step - loss: 0.0382 - accuracy: 0.9761 - mean_io_u_1: 0.5546 - f1_m: 0.9761 - val_loss: 0.1088 - val_accuracy: 0.9348 - val_mean_io_u_1: 0.5412 - val_f1_m: 0.9348\n",
      "Epoch 18/50\n",
      "883/883 [==============================] - 674s 763ms/step - loss: 0.0362 - accuracy: 0.9773 - mean_io_u_1: 0.5563 - f1_m: 0.9773 - val_loss: 0.1093 - val_accuracy: 0.9347 - val_mean_io_u_1: 0.5420 - val_f1_m: 0.9347\n",
      "Epoch 19/50\n",
      "883/883 [==============================] - 674s 763ms/step - loss: 0.0340 - accuracy: 0.9786 - mean_io_u_1: 0.5587 - f1_m: 0.9786 - val_loss: 0.1093 - val_accuracy: 0.9347 - val_mean_io_u_1: 0.5437 - val_f1_m: 0.9347\n",
      "Epoch 20/50\n",
      "883/883 [==============================] - 674s 763ms/step - loss: 0.0328 - accuracy: 0.9794 - mean_io_u_1: 0.5600 - f1_m: 0.9794 - val_loss: 0.1098 - val_accuracy: 0.9347 - val_mean_io_u_1: 0.5450 - val_f1_m: 0.9347\n",
      "Epoch 21/50\n",
      "883/883 [==============================] - 675s 764ms/step - loss: 0.0312 - accuracy: 0.9804 - mean_io_u_1: 0.5619 - f1_m: 0.9804 - val_loss: 0.1104 - val_accuracy: 0.9345 - val_mean_io_u_1: 0.5459 - val_f1_m: 0.9345\n",
      "Epoch 22/50\n",
      "883/883 [==============================] - 674s 763ms/step - loss: 0.0295 - accuracy: 0.9813 - mean_io_u_1: 0.5649 - f1_m: 0.9813 - val_loss: 0.1108 - val_accuracy: 0.9344 - val_mean_io_u_1: 0.5469 - val_f1_m: 0.9344\n",
      "Epoch 23/50\n",
      "883/883 [==============================] - 674s 763ms/step - loss: 0.0285 - accuracy: 0.9820 - mean_io_u_1: 0.5666 - f1_m: 0.9820 - val_loss: 0.1109 - val_accuracy: 0.9347 - val_mean_io_u_1: 0.5495 - val_f1_m: 0.9347\n",
      "Epoch 24/50\n",
      "883/883 [==============================] - 673s 761ms/step - loss: 0.0272 - accuracy: 0.9828 - mean_io_u_1: 0.5690 - f1_m: 0.9828 - val_loss: 0.1116 - val_accuracy: 0.9344 - val_mean_io_u_1: 0.5506 - val_f1_m: 0.9344\n",
      "Epoch 25/50\n",
      "883/883 [==============================] - 672s 761ms/step - loss: 0.0259 - accuracy: 0.9836 - mean_io_u_1: 0.5725 - f1_m: 0.9836 - val_loss: 0.1120 - val_accuracy: 0.9344 - val_mean_io_u_1: 0.5530 - val_f1_m: 0.9344\n",
      "Epoch 26/50\n",
      "883/883 [==============================] - 672s 761ms/step - loss: 0.0251 - accuracy: 0.9841 - mean_io_u_1: 0.5748 - f1_m: 0.9841 - val_loss: 0.1127 - val_accuracy: 0.9344 - val_mean_io_u_1: 0.5577 - val_f1_m: 0.9344\n",
      "Epoch 27/50\n",
      "883/883 [==============================] - 672s 760ms/step - loss: 0.0241 - accuracy: 0.9847 - mean_io_u_1: 0.5771 - f1_m: 0.9847 - val_loss: 0.1133 - val_accuracy: 0.9342 - val_mean_io_u_1: 0.5580 - val_f1_m: 0.9342\n",
      "Epoch 28/50\n",
      "883/883 [==============================] - 672s 761ms/step - loss: 0.0231 - accuracy: 0.9853 - mean_io_u_1: 0.5810 - f1_m: 0.9853 - val_loss: 0.1139 - val_accuracy: 0.9340 - val_mean_io_u_1: 0.5608 - val_f1_m: 0.9340\n",
      "Epoch 29/50\n",
      "883/883 [==============================] - 672s 760ms/step - loss: 0.0224 - accuracy: 0.9857 - mean_io_u_1: 0.5834 - f1_m: 0.9857 - val_loss: 0.1143 - val_accuracy: 0.9342 - val_mean_io_u_1: 0.5640 - val_f1_m: 0.9342\n",
      "Epoch 30/50\n",
      "883/883 [==============================] - 674s 763ms/step - loss: 0.0217 - accuracy: 0.9861 - mean_io_u_1: 0.5858 - f1_m: 0.9861 - val_loss: 0.1151 - val_accuracy: 0.9338 - val_mean_io_u_1: 0.5643 - val_f1_m: 0.9338\n",
      "Epoch 31/50\n",
      "883/883 [==============================] - 672s 760ms/step - loss: 0.0210 - accuracy: 0.9865 - mean_io_u_1: 0.5895 - f1_m: 0.9865 - val_loss: 0.1155 - val_accuracy: 0.9337 - val_mean_io_u_1: 0.5666 - val_f1_m: 0.9337\n",
      "Epoch 32/50\n",
      "883/883 [==============================] - 673s 762ms/step - loss: 0.0206 - accuracy: 0.9868 - mean_io_u_1: 0.5916 - f1_m: 0.9868 - val_loss: 0.1157 - val_accuracy: 0.9341 - val_mean_io_u_1: 0.5721 - val_f1_m: 0.9341\n",
      "Epoch 33/50\n",
      "883/883 [==============================] - 674s 763ms/step - loss: 0.0202 - accuracy: 0.9870 - mean_io_u_1: 0.5936 - f1_m: 0.9870 - val_loss: 0.1158 - val_accuracy: 0.9340 - val_mean_io_u_1: 0.5706 - val_f1_m: 0.9340\n",
      "Epoch 34/50\n",
      "883/883 [==============================] - 673s 762ms/step - loss: 0.0197 - accuracy: 0.9873 - mean_io_u_1: 0.5967 - f1_m: 0.9873 - val_loss: 0.1167 - val_accuracy: 0.9336 - val_mean_io_u_1: 0.5717 - val_f1_m: 0.9336\n",
      "Epoch 35/50\n",
      "883/883 [==============================] - 673s 762ms/step - loss: 0.0194 - accuracy: 0.9875 - mean_io_u_1: 0.5983 - f1_m: 0.9875 - val_loss: 0.1168 - val_accuracy: 0.9339 - val_mean_io_u_1: 0.5770 - val_f1_m: 0.9339\n",
      "Epoch 36/50\n",
      "883/883 [==============================] - 670s 759ms/step - loss: 0.0190 - accuracy: 0.9877 - mean_io_u_1: 0.5998 - f1_m: 0.9877 - val_loss: 0.1165 - val_accuracy: 0.9341 - val_mean_io_u_1: 0.5751 - val_f1_m: 0.9341\n",
      "Epoch 37/50\n",
      "883/883 [==============================] - 671s 759ms/step - loss: 0.0186 - accuracy: 0.9880 - mean_io_u_1: 0.6024 - f1_m: 0.9880 - val_loss: 0.1176 - val_accuracy: 0.9337 - val_mean_io_u_1: 0.5779 - val_f1_m: 0.9337\n",
      "Epoch 38/50\n",
      "883/883 [==============================] - 673s 761ms/step - loss: 0.0182 - accuracy: 0.9882 - mean_io_u_1: 0.6039 - f1_m: 0.9882 - val_loss: 0.1177 - val_accuracy: 0.9337 - val_mean_io_u_1: 0.5782 - val_f1_m: 0.9337\n",
      "Epoch 39/50\n",
      "883/883 [==============================] - 672s 761ms/step - loss: 0.0178 - accuracy: 0.9885 - mean_io_u_1: 0.6052 - f1_m: 0.9885 - val_loss: 0.1175 - val_accuracy: 0.9339 - val_mean_io_u_1: 0.5795 - val_f1_m: 0.9339\n",
      "Epoch 40/50\n",
      "883/883 [==============================] - 671s 759ms/step - loss: 0.0175 - accuracy: 0.9886 - mean_io_u_1: 0.6077 - f1_m: 0.9886 - val_loss: 0.1179 - val_accuracy: 0.9337 - val_mean_io_u_1: 0.5786 - val_f1_m: 0.9337\n",
      "Epoch 41/50\n",
      "883/883 [==============================] - 673s 762ms/step - loss: 0.0173 - accuracy: 0.9888 - mean_io_u_1: 0.6091 - f1_m: 0.9888 - val_loss: 0.1193 - val_accuracy: 0.9334 - val_mean_io_u_1: 0.5834 - val_f1_m: 0.9334\n",
      "Epoch 42/50\n",
      "883/883 [==============================] - 673s 762ms/step - loss: 0.0169 - accuracy: 0.9890 - mean_io_u_1: 0.6107 - f1_m: 0.9890 - val_loss: 0.1187 - val_accuracy: 0.9337 - val_mean_io_u_1: 0.5827 - val_f1_m: 0.9337\n",
      "Epoch 43/50\n",
      "883/883 [==============================] - 673s 762ms/step - loss: 0.0167 - accuracy: 0.9892 - mean_io_u_1: 0.6129 - f1_m: 0.9892 - val_loss: 0.1193 - val_accuracy: 0.9336 - val_mean_io_u_1: 0.5857 - val_f1_m: 0.9336\n",
      "Epoch 44/50\n",
      "883/883 [==============================] - 672s 761ms/step - loss: 0.0165 - accuracy: 0.9893 - mean_io_u_1: 0.6147 - f1_m: 0.9893 - val_loss: 0.1191 - val_accuracy: 0.9339 - val_mean_io_u_1: 0.5886 - val_f1_m: 0.9339\n",
      "Epoch 45/50\n",
      "883/883 [==============================] - 674s 763ms/step - loss: 0.0163 - accuracy: 0.9894 - mean_io_u_1: 0.6158 - f1_m: 0.9894 - val_loss: 0.1196 - val_accuracy: 0.9334 - val_mean_io_u_1: 0.5833 - val_f1_m: 0.9334\n",
      "Epoch 46/50\n",
      "883/883 [==============================] - 674s 762ms/step - loss: 0.0160 - accuracy: 0.9896 - mean_io_u_1: 0.6183 - f1_m: 0.9896 - val_loss: 0.1198 - val_accuracy: 0.9336 - val_mean_io_u_1: 0.5898 - val_f1_m: 0.9336\n",
      "Epoch 47/50\n",
      "883/883 [==============================] - 673s 762ms/step - loss: 0.0158 - accuracy: 0.9897 - mean_io_u_1: 0.6191 - f1_m: 0.9897 - val_loss: 0.1211 - val_accuracy: 0.9331 - val_mean_io_u_1: 0.5899 - val_f1_m: 0.9331\n",
      "Epoch 48/50\n",
      "883/883 [==============================] - 673s 762ms/step - loss: 0.0155 - accuracy: 0.9899 - mean_io_u_1: 0.6207 - f1_m: 0.9899 - val_loss: 0.1202 - val_accuracy: 0.9338 - val_mean_io_u_1: 0.5936 - val_f1_m: 0.9338\n",
      "Epoch 49/50\n",
      "883/883 [==============================] - 673s 762ms/step - loss: 0.0153 - accuracy: 0.9901 - mean_io_u_1: 0.6228 - f1_m: 0.9901 - val_loss: 0.1208 - val_accuracy: 0.9333 - val_mean_io_u_1: 0.5897 - val_f1_m: 0.9333\n",
      "Epoch 50/50\n",
      "883/883 [==============================] - 673s 762ms/step - loss: 0.0151 - accuracy: 0.9901 - mean_io_u_1: 0.6241 - f1_m: 0.9901 - val_loss: 0.1209 - val_accuracy: 0.9336 - val_mean_io_u_1: 0.5963 - val_f1_m: 0.9336\n"
     ]
    }
   ],
   "source": [
    "import segmentation_models as sm\r\n",
    "n_classes = 6\r\n",
    "dice_loss = sm.losses.DiceLoss()\r\n",
    "focal_loss = sm.losses.BinaryFocalLoss() if n_classes == 1 else sm.losses.CategoricalFocalLoss()\r\n",
    "total_loss = dice_loss + (1 * focal_loss)\r\n",
    "\r\n",
    "with tf.device('/gpu:0'):\r\n",
    "    model.train(\r\n",
    "        train_images =  trainimg_dir,\r\n",
    "        train_annotations = trainmsk_dir,\r\n",
    "        batch_size=batch,\r\n",
    "        val_images=valimg_dir,\r\n",
    "        val_annotations=valmsk_dir,\r\n",
    "        val_batch_size=batch,\r\n",
    "        checkpoints_path = \"segnet\",\r\n",
    "        callbacks = callbacks,\r\n",
    "        epochs=EPOCHS,\r\n",
    "        verify_dataset=None,\r\n",
    "        steps_per_epoch=train_steps,\r\n",
    "        val_steps_per_epoch=val_steps,\r\n",
    "        validate = True,\r\n",
    "        fine_tuning = True,\r\n",
    "        layer_fine_tuning = 'bn5c_branch2c',\r\n",
    "        learning_rate = LR,\r\n",
    "        loss = total_loss\r\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2727it [05:41,  7.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'frequency_weighted_IU': 0.9043723983835286, 'mean_IU': 0.7670220757970758, 'class_wise_IU': array([0.58996104, 0.94408311])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(path_weight)\r\n",
    "\r\n",
    "from keras_segmentation.predict import evaluate\r\n",
    "\r\n",
    "out = evaluate(model,\r\n",
    "    inp_images_dir= testimg_dir,\r\n",
    "    annotations_dir = testmsk_dir\r\n",
    ")\r\n",
    "\r\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Unet1 - Train.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "694ac46796b4ee334d5074a2c14193d73c4de6000732ca8f993bd774733feef2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

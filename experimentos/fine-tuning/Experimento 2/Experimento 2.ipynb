{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ProjetoCastasTodasv2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWd4dMSSHSIT"
      },
      "source": [
        "import keras, math\n",
        "from keras import preprocessing, applications\n",
        "from keras.applications.xception import Xception, preprocess_input\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from functools import partial, update_wrapper\n",
        "import datetime\n",
        "from keras import backend as K\n",
        "from sklearn import metrics\n",
        "import itertools\n",
        "from keras.layers import Conv2D, Dense, MaxPooling2D, Flatten, Dropout, BatchNormalization, GlobalMaxPooling2D\n",
        "from keras.optimizers import Adam,RMSprop, SGD\n",
        "from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "from requests import get\n",
        "from google.colab import drive\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic65q5B6Hc4B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c82207b8-d30f-42f5-9cf7-84eceb824299"
      },
      "source": [
        "!wget --output-document dataset.zip https://www.dropbox.com/s/lh7sqc1xtjo6duw/dataset_aumentado_todas.zip?dl=0\n",
        "!unzip -o -q dataset.zip\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "nome_treino = get('http://172.28.0.2:9000/api/sessions').json()[0]['name'].split(\".\")[0]+'/'\n",
        "diretorio = '/content/dataset_aumentado/'\n",
        "dir_teste = os.path.join(diretorio, 'test')\n",
        "dir_treino = os.path.join(diretorio, 'train')\n",
        "dir_validation = os.path.join(diretorio, 'validation')\n",
        "dir_pesos = '/content/gdrive/MyDrive/pesos/'\n",
        "dir_pesos_model = dir_pesos+nome_treino\n",
        "latest = '/content/gdrive/MyDrive/ana/exp 1/model_checkpoint_weights_callback.weights.best.hdf5'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-24 15:33:55--  https://www.dropbox.com/s/lh7sqc1xtjo6duw/dataset_aumentado_todas.zip?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.2.18, 2620:100:6017:18::a27d:212\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.2.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/lh7sqc1xtjo6duw/dataset_aumentado_todas.zip [following]\n",
            "--2021-06-24 15:33:55--  https://www.dropbox.com/s/raw/lh7sqc1xtjo6duw/dataset_aumentado_todas.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc392f9809da648d1bcad99ce9a5.dl.dropboxusercontent.com/cd/0/inline/BRA6kLi_WA4IHCv5G0ZrM1Xc_u_8A5y6UZBmjXLBKGNxG4jYCzggbeY256TymEvCMDLKSAhXAmkMFIwO9OQpFtb2P440DFPK-qkoJsIuM1GwXMPkLCCLEI6miwUfWX6xkcnR4GPSSR7bUK0Tw96Kkp3e/file# [following]\n",
            "--2021-06-24 15:33:56--  https://uc392f9809da648d1bcad99ce9a5.dl.dropboxusercontent.com/cd/0/inline/BRA6kLi_WA4IHCv5G0ZrM1Xc_u_8A5y6UZBmjXLBKGNxG4jYCzggbeY256TymEvCMDLKSAhXAmkMFIwO9OQpFtb2P440DFPK-qkoJsIuM1GwXMPkLCCLEI6miwUfWX6xkcnR4GPSSR7bUK0Tw96Kkp3e/file\n",
            "Resolving uc392f9809da648d1bcad99ce9a5.dl.dropboxusercontent.com (uc392f9809da648d1bcad99ce9a5.dl.dropboxusercontent.com)... 162.125.4.15, 2620:100:6017:15::a27d:20f\n",
            "Connecting to uc392f9809da648d1bcad99ce9a5.dl.dropboxusercontent.com (uc392f9809da648d1bcad99ce9a5.dl.dropboxusercontent.com)|162.125.4.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BRCHLAqeRlKoDpWEhUK9JFAGFcUvLzZj_TtWEtZyNJ7APz7ri9FVi_IY1VPY6fUyd98Rh9XMFupPMpWIwgLTjEavQL8ZczeGaFzcPkA0T1bPEYReluDwliJ3THfmkOxEUkyvlqqRnd5BLoJW_yQeKRJhQe6BnDr5F23R6vi03kMNIqD4WsDuvAAj33BRv-8ka6yLDChcSXOwI80eMFlN_xcncfY0tMTArrKVKHm-A2TdvKcjqEPSJH6CZR5kDfGE_O3598_nyMt6ttBsVVwv8Q_R5tvK2ryfxTNeUzjzqEigx51W49i6PYXjbSa8tnut0Gp32OXD9jHs192MyXWsfDiony7lLZJZeoRd2SwQQ-jQRX2bMQtOJIWtE_ieEsE3eyk/file [following]\n",
            "--2021-06-24 15:33:56--  https://uc392f9809da648d1bcad99ce9a5.dl.dropboxusercontent.com/cd/0/inline2/BRCHLAqeRlKoDpWEhUK9JFAGFcUvLzZj_TtWEtZyNJ7APz7ri9FVi_IY1VPY6fUyd98Rh9XMFupPMpWIwgLTjEavQL8ZczeGaFzcPkA0T1bPEYReluDwliJ3THfmkOxEUkyvlqqRnd5BLoJW_yQeKRJhQe6BnDr5F23R6vi03kMNIqD4WsDuvAAj33BRv-8ka6yLDChcSXOwI80eMFlN_xcncfY0tMTArrKVKHm-A2TdvKcjqEPSJH6CZR5kDfGE_O3598_nyMt6ttBsVVwv8Q_R5tvK2ryfxTNeUzjzqEigx51W49i6PYXjbSa8tnut0Gp32OXD9jHs192MyXWsfDiony7lLZJZeoRd2SwQQ-jQRX2bMQtOJIWtE_ieEsE3eyk/file\n",
            "Reusing existing connection to uc392f9809da648d1bcad99ce9a5.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 114331238 (109M) [application/zip]\n",
            "Saving to: ‘dataset.zip’\n",
            "\n",
            "dataset.zip         100%[===================>] 109.03M  33.6MB/s    in 3.5s    \n",
            "\n",
            "2021-06-24 15:34:00 (30.8 MB/s) - ‘dataset.zip’ saved [114331238/114331238]\n",
            "\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgoNhHrrHePA",
        "outputId": "8a52c899-0595-4eca-8a67-a1365432dc9f"
      },
      "source": [
        "\n",
        "#definição do data augmentation e geradores de treino, teste e validacao\n",
        "batch = 12\n",
        "target_size_dimension= 300\n",
        "#peso para cada uma das classes, como o generator organiza as classes de maneira alfanumerica, basta ordenar\n",
        "#por nome que se consegue obter os repesctivos pesos de cada umas das classes\n",
        "\n",
        "pesos_por_classe = [0.09005656445370647, 0.08023221196784758, 0.08008335814230426, 0.08484668055969039,\n",
        "                    0.07368264364394166, 0.08350699612980053, 0.07695742780589461, 0.08350699612980053,\n",
        "                    0.0867817802917535, 0.09333134861565942, 0.08186960404882405, 0.08514438821077702]\n",
        "\n",
        "\n",
        "treino_datagen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=keras.applications.xception.preprocess_input)\n",
        "\n",
        "validacao_datagen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=keras.applications.xception.preprocess_input)\n",
        "\n",
        "teste_datagen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=keras.applications.xception.preprocess_input)\n",
        "\n",
        "treino_set = treino_datagen.flow_from_directory(dir_treino,\n",
        "                                              target_size=(target_size_dimension, target_size_dimension),\n",
        "                                              class_mode='categorical',\n",
        "                                              batch_size=batch)\n",
        "\n",
        "validacao_set = treino_datagen.flow_from_directory(dir_validation,\n",
        "                                              target_size=(target_size_dimension, target_size_dimension),\n",
        "                                              class_mode='categorical',\n",
        "                                              batch_size=batch)\n",
        "\n",
        "teste_set = teste_datagen.flow_from_directory(dir_teste, \n",
        "                                            target_size=(target_size_dimension, target_size_dimension),\n",
        "                                            class_mode='categorical',\n",
        "                                            batch_size=1,\n",
        "                                            shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6718 images belonging to 12 classes.\n",
            "Found 132 images belonging to 12 classes.\n",
            "Found 72 images belonging to 12 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA_eddaLIndg"
      },
      "source": [
        "def focal_loss(gamma=2., alpha=4.):\n",
        "\n",
        "    gamma = float(gamma)\n",
        "    alpha = float(alpha)\n",
        "\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        epsilon = 1.e-9\n",
        "        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
        "        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
        "\n",
        "        model_out = tf.add(y_pred, epsilon)\n",
        "        ce = tf.multiply(y_true, -tf.math.log(model_out))\n",
        "        weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma))\n",
        "        fl = tf.multiply(alpha, tf.multiply(weight, ce))\n",
        "        reduced_fl = tf.reduce_max(fl, axis=1)\n",
        "        return tf.reduce_mean(reduced_fl)\n",
        "    return focal_loss_fixed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Hz9o9luIqyl"
      },
      "source": [
        "#step decay\n",
        "def step_decay(epoch):\n",
        "   initial_lrate = 0.1\n",
        "   flattern_factor = initial_lrate ** 2.25\n",
        "   epochs_drop = 5.0\n",
        "   drop = initial_lrate **(flattern_factor/epochs_drop)\n",
        "   \n",
        "   lrate = initial_lrate * math.pow(drop,  \n",
        "           math.floor((epoch)/epochs_drop))\n",
        "   return lrate\n",
        "\n",
        "#exp decay\n",
        "def exp_decay(epoch):\n",
        "   initial_lrate = 0.1\n",
        "   n_epochs = 5.0\n",
        "   flattern_factor = initial_lrate ** 2.25\n",
        "   #eu realmente nao entendi isso aqui\n",
        "   k = math.log((initial_lrate**flattern_factor)/initial_lrate)/(n_epochs*math.log(math.e))\n",
        "   lrate = initial_lrate * math.exp(-k*epoch)\n",
        "   return lrate\n",
        "\n",
        "\n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "       self.losses = []\n",
        "       self.lr = []\n",
        " \n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "       self.losses.append(logs.get('loss'))\n",
        "       self.lr.append(step_decay(len(self.losses)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxltdfzxIres"
      },
      "source": [
        "def get_f1(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val\n",
        "\n",
        "def recall_function(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_function(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_function(y_true, y_pred):\n",
        "    precision = precision_function(y_true, y_pred)\n",
        "    recall = recall_function(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmL3xpVtIu5v",
        "outputId": "ba21d268-121e-494d-e00e-1ec3d541b005"
      },
      "source": [
        "model = Xception(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    pooling='avg',\n",
        "    input_shape=(target_size_dimension, target_size_dimension, 3)\n",
        ")\n",
        "\n",
        "#fine_tune = 133\n",
        "\n",
        "x = Dense(40, activation='relu')(model.output)\n",
        "x = Dropout(0.25)(x)\n",
        "output = Dense(12, activation='softmax')(x)\n",
        "model_novo = keras.models.Model(model.input, output)\n",
        "model_novo.load_weights(latest)\n",
        "\n",
        "'''\n",
        "if fine_tune > 0:\n",
        "   for layer in model.layers[:-fine_tune]:\n",
        "            layer.trainable = False\n",
        "else:\n",
        "   for layer in model.layers:\n",
        "            layer.trainable = False\n",
        "'''\n",
        "\n",
        "loss_history = LossHistory()\n",
        "#lrate = LearningRateScheduler(exp_decay)\n",
        "estop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15)\n",
        "lrate = LearningRateScheduler(step_decay)\n",
        "\n",
        "model_checkpoint_weights_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=dir_pesos_model,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_f1_function',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "callbacks_list = [loss_history, estop, lrate, model_checkpoint_weights_callback]\n",
        "\n",
        "def setup_model (model_novo, fine_tune):\n",
        "  for layer in model_novo.layers [:(len(model_novo.layers)-fine_tune)]:\n",
        "    layer.trainable = False\n",
        "  for layer in model_novo.layers [(len(model_novo.layers)-fine_tune):]:\n",
        "    layer.trainable = True\n",
        "\n",
        "  \n",
        "\n",
        "#model_novo.compile(optimizer='sgd', loss=focal_loss(alpha=1), metrics=['accuracy', f1_function,precision_function, recall_function])\n",
        "#setup_model(model_novo,20)\n",
        "\n",
        "#Mostra a duração do tempo de treinamento do modelo\n",
        "start = datetime.now()\n",
        "\n",
        "for i, layer in enumerate(model_novo.layers):\n",
        "  print(i, layer.name, layer.trainable)\n",
        "\n",
        "model_novo.compile(optimizer='sgd', loss=focal_loss(alpha=1), metrics=['accuracy', f1_function, precision_function, recall_function])\n",
        "\n",
        "history = model_novo.fit(treino_set, steps_per_epoch=treino_set.samples/batch,\n",
        "              epochs=100, validation_data=validacao_set, validation_steps=validacao_set.samples/batch, shuffle=True, verbose=True, callbacks=callbacks_list)\n",
        "\n",
        "duracao=datetime.now() - start\n",
        "print(\"Treino completo no tempo: \", duracao)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 input_2 True\n",
            "1 block1_conv1 True\n",
            "2 block1_conv1_bn True\n",
            "3 block1_conv1_act True\n",
            "4 block1_conv2 True\n",
            "5 block1_conv2_bn True\n",
            "6 block1_conv2_act True\n",
            "7 block2_sepconv1 True\n",
            "8 block2_sepconv1_bn True\n",
            "9 block2_sepconv2_act True\n",
            "10 block2_sepconv2 True\n",
            "11 block2_sepconv2_bn True\n",
            "12 conv2d_4 True\n",
            "13 block2_pool True\n",
            "14 batch_normalization_4 True\n",
            "15 add_12 True\n",
            "16 block3_sepconv1_act True\n",
            "17 block3_sepconv1 True\n",
            "18 block3_sepconv1_bn True\n",
            "19 block3_sepconv2_act True\n",
            "20 block3_sepconv2 True\n",
            "21 block3_sepconv2_bn True\n",
            "22 conv2d_5 True\n",
            "23 block3_pool True\n",
            "24 batch_normalization_5 True\n",
            "25 add_13 True\n",
            "26 block4_sepconv1_act True\n",
            "27 block4_sepconv1 True\n",
            "28 block4_sepconv1_bn True\n",
            "29 block4_sepconv2_act True\n",
            "30 block4_sepconv2 True\n",
            "31 block4_sepconv2_bn True\n",
            "32 conv2d_6 True\n",
            "33 block4_pool True\n",
            "34 batch_normalization_6 True\n",
            "35 add_14 True\n",
            "36 block5_sepconv1_act True\n",
            "37 block5_sepconv1 True\n",
            "38 block5_sepconv1_bn True\n",
            "39 block5_sepconv2_act True\n",
            "40 block5_sepconv2 True\n",
            "41 block5_sepconv2_bn True\n",
            "42 block5_sepconv3_act True\n",
            "43 block5_sepconv3 True\n",
            "44 block5_sepconv3_bn True\n",
            "45 add_15 True\n",
            "46 block6_sepconv1_act True\n",
            "47 block6_sepconv1 True\n",
            "48 block6_sepconv1_bn True\n",
            "49 block6_sepconv2_act True\n",
            "50 block6_sepconv2 True\n",
            "51 block6_sepconv2_bn True\n",
            "52 block6_sepconv3_act True\n",
            "53 block6_sepconv3 True\n",
            "54 block6_sepconv3_bn True\n",
            "55 add_16 True\n",
            "56 block7_sepconv1_act True\n",
            "57 block7_sepconv1 True\n",
            "58 block7_sepconv1_bn True\n",
            "59 block7_sepconv2_act True\n",
            "60 block7_sepconv2 True\n",
            "61 block7_sepconv2_bn True\n",
            "62 block7_sepconv3_act True\n",
            "63 block7_sepconv3 True\n",
            "64 block7_sepconv3_bn True\n",
            "65 add_17 True\n",
            "66 block8_sepconv1_act True\n",
            "67 block8_sepconv1 True\n",
            "68 block8_sepconv1_bn True\n",
            "69 block8_sepconv2_act True\n",
            "70 block8_sepconv2 True\n",
            "71 block8_sepconv2_bn True\n",
            "72 block8_sepconv3_act True\n",
            "73 block8_sepconv3 True\n",
            "74 block8_sepconv3_bn True\n",
            "75 add_18 True\n",
            "76 block9_sepconv1_act True\n",
            "77 block9_sepconv1 True\n",
            "78 block9_sepconv1_bn True\n",
            "79 block9_sepconv2_act True\n",
            "80 block9_sepconv2 True\n",
            "81 block9_sepconv2_bn True\n",
            "82 block9_sepconv3_act True\n",
            "83 block9_sepconv3 True\n",
            "84 block9_sepconv3_bn True\n",
            "85 add_19 True\n",
            "86 block10_sepconv1_act True\n",
            "87 block10_sepconv1 True\n",
            "88 block10_sepconv1_bn True\n",
            "89 block10_sepconv2_act True\n",
            "90 block10_sepconv2 True\n",
            "91 block10_sepconv2_bn True\n",
            "92 block10_sepconv3_act True\n",
            "93 block10_sepconv3 True\n",
            "94 block10_sepconv3_bn True\n",
            "95 add_20 True\n",
            "96 block11_sepconv1_act True\n",
            "97 block11_sepconv1 True\n",
            "98 block11_sepconv1_bn True\n",
            "99 block11_sepconv2_act True\n",
            "100 block11_sepconv2 True\n",
            "101 block11_sepconv2_bn True\n",
            "102 block11_sepconv3_act True\n",
            "103 block11_sepconv3 True\n",
            "104 block11_sepconv3_bn True\n",
            "105 add_21 True\n",
            "106 block12_sepconv1_act True\n",
            "107 block12_sepconv1 True\n",
            "108 block12_sepconv1_bn True\n",
            "109 block12_sepconv2_act True\n",
            "110 block12_sepconv2 True\n",
            "111 block12_sepconv2_bn True\n",
            "112 block12_sepconv3_act True\n",
            "113 block12_sepconv3 True\n",
            "114 block12_sepconv3_bn True\n",
            "115 add_22 True\n",
            "116 block13_sepconv1_act True\n",
            "117 block13_sepconv1 True\n",
            "118 block13_sepconv1_bn True\n",
            "119 block13_sepconv2_act True\n",
            "120 block13_sepconv2 True\n",
            "121 block13_sepconv2_bn True\n",
            "122 conv2d_7 True\n",
            "123 block13_pool True\n",
            "124 batch_normalization_7 True\n",
            "125 add_23 True\n",
            "126 block14_sepconv1 True\n",
            "127 block14_sepconv1_bn True\n",
            "128 block14_sepconv1_act True\n",
            "129 block14_sepconv2 True\n",
            "130 block14_sepconv2_bn True\n",
            "131 block14_sepconv2_act True\n",
            "132 global_average_pooling2d_1 True\n",
            "133 dense_2 True\n",
            "134 dropout_1 True\n",
            "135 dense_3 True\n",
            "Epoch 1/100\n",
            "  6/559 [..............................] - ETA: 3:58 - loss: 0.0039 - accuracy: 1.0000 - f1_function: 0.9955 - precision_function: 1.0000 - recall_function: 0.9914WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1229s vs `on_train_batch_end` time: 0.2566s). Check your callbacks.\n",
            "559/559 [==============================] - 313s 463ms/step - loss: 0.0014 - accuracy: 0.9994 - f1_function: 0.9987 - precision_function: 0.9995 - recall_function: 0.9980 - val_loss: 0.1788 - val_accuracy: 0.9242 - val_f1_function: 0.9114 - val_precision_function: 0.9222 - val_recall_function: 0.9015\n",
            "Epoch 2/100\n",
            "559/559 [==============================] - 255s 455ms/step - loss: 0.0055 - accuracy: 0.9966 - f1_function: 0.9962 - precision_function: 0.9979 - recall_function: 0.9947 - val_loss: 0.1645 - val_accuracy: 0.9167 - val_f1_function: 0.9233 - val_precision_function: 0.9304 - val_recall_function: 0.9167\n",
            "Epoch 3/100\n",
            "559/559 [==============================] - 254s 454ms/step - loss: 0.0016 - accuracy: 0.9990 - f1_function: 0.9983 - precision_function: 0.9993 - recall_function: 0.9973 - val_loss: 0.2003 - val_accuracy: 0.9167 - val_f1_function: 0.9226 - val_precision_function: 0.9373 - val_recall_function: 0.9091\n",
            "Epoch 4/100\n",
            "559/559 [==============================] - 254s 454ms/step - loss: 0.0015 - accuracy: 0.9990 - f1_function: 0.9986 - precision_function: 0.9991 - recall_function: 0.9981 - val_loss: 0.2615 - val_accuracy: 0.8788 - val_f1_function: 0.8811 - val_precision_function: 0.8919 - val_recall_function: 0.8712\n",
            "Epoch 5/100\n",
            "559/559 [==============================] - 255s 455ms/step - loss: 9.7777e-04 - accuracy: 0.9997 - f1_function: 0.9994 - precision_function: 0.9999 - recall_function: 0.9990 - val_loss: 0.2765 - val_accuracy: 0.8788 - val_f1_function: 0.8850 - val_precision_function: 0.8919 - val_recall_function: 0.8788\n",
            "Epoch 6/100\n",
            "559/559 [==============================] - 254s 453ms/step - loss: 0.0061 - accuracy: 0.9963 - f1_function: 0.9963 - precision_function: 0.9970 - recall_function: 0.9956 - val_loss: 0.2921 - val_accuracy: 0.8788 - val_f1_function: 0.8755 - val_precision_function: 0.8974 - val_recall_function: 0.8561\n",
            "Epoch 7/100\n",
            "559/559 [==============================] - 254s 454ms/step - loss: 0.0021 - accuracy: 0.9977 - f1_function: 0.9979 - precision_function: 0.9992 - recall_function: 0.9966 - val_loss: 0.3233 - val_accuracy: 0.8636 - val_f1_function: 0.8613 - val_precision_function: 0.8671 - val_recall_function: 0.8561\n",
            "Epoch 8/100\n",
            "559/559 [==============================] - 255s 455ms/step - loss: 0.0016 - accuracy: 0.9989 - f1_function: 0.9988 - precision_function: 0.9993 - recall_function: 0.9984 - val_loss: 0.3504 - val_accuracy: 0.9015 - val_f1_function: 0.8926 - val_precision_function: 0.8994 - val_recall_function: 0.8864\n",
            "Epoch 9/100\n",
            "559/559 [==============================] - 255s 455ms/step - loss: 0.0027 - accuracy: 0.9981 - f1_function: 0.9983 - precision_function: 0.9992 - recall_function: 0.9975 - val_loss: 0.3272 - val_accuracy: 0.8864 - val_f1_function: 0.8930 - val_precision_function: 0.9001 - val_recall_function: 0.8864\n",
            "Epoch 10/100\n",
            "559/559 [==============================] - 254s 454ms/step - loss: 0.0026 - accuracy: 0.9994 - f1_function: 0.9993 - precision_function: 0.9994 - recall_function: 0.9991 - val_loss: 0.2335 - val_accuracy: 0.8939 - val_f1_function: 0.9005 - val_precision_function: 0.9077 - val_recall_function: 0.8939\n",
            "Epoch 11/100\n",
            "559/559 [==============================] - 255s 455ms/step - loss: 0.0021 - accuracy: 0.9988 - f1_function: 0.9985 - precision_function: 0.9989 - recall_function: 0.9981 - val_loss: 0.2352 - val_accuracy: 0.8864 - val_f1_function: 0.8844 - val_precision_function: 0.8988 - val_recall_function: 0.8712\n",
            "Epoch 12/100\n",
            "559/559 [==============================] - 255s 455ms/step - loss: 9.3329e-04 - accuracy: 0.9998 - f1_function: 0.9994 - precision_function: 0.9999 - recall_function: 0.9990 - val_loss: 0.3885 - val_accuracy: 0.8485 - val_f1_function: 0.8382 - val_precision_function: 0.8523 - val_recall_function: 0.8258\n",
            "Epoch 13/100\n",
            "559/559 [==============================] - 254s 455ms/step - loss: 0.0025 - accuracy: 0.9982 - f1_function: 0.9986 - precision_function: 0.9993 - recall_function: 0.9979 - val_loss: 0.2866 - val_accuracy: 0.8712 - val_f1_function: 0.8738 - val_precision_function: 0.8850 - val_recall_function: 0.8636\n",
            "Epoch 14/100\n",
            "559/559 [==============================] - 255s 456ms/step - loss: 7.8823e-04 - accuracy: 0.9993 - f1_function: 0.9993 - precision_function: 0.9993 - recall_function: 0.9992 - val_loss: 0.2563 - val_accuracy: 0.9091 - val_f1_function: 0.9009 - val_precision_function: 0.9084 - val_recall_function: 0.8939\n",
            "Epoch 15/100\n",
            "559/559 [==============================] - 255s 455ms/step - loss: 0.0010 - accuracy: 0.9987 - f1_function: 0.9988 - precision_function: 0.9993 - recall_function: 0.9982 - val_loss: 0.3865 - val_accuracy: 0.8712 - val_f1_function: 0.8748 - val_precision_function: 0.8788 - val_recall_function: 0.8712\n",
            "Epoch 16/100\n",
            "559/559 [==============================] - 255s 455ms/step - loss: 7.4066e-04 - accuracy: 0.9995 - f1_function: 0.9995 - precision_function: 0.9998 - recall_function: 0.9993 - val_loss: 0.3801 - val_accuracy: 0.8788 - val_f1_function: 0.8785 - val_precision_function: 0.8864 - val_recall_function: 0.8712\n",
            "Epoch 17/100\n",
            "559/559 [==============================] - 255s 455ms/step - loss: 0.0019 - accuracy: 0.9983 - f1_function: 0.9985 - precision_function: 0.9989 - recall_function: 0.9982 - val_loss: 0.2630 - val_accuracy: 0.9015 - val_f1_function: 0.8959 - val_precision_function: 0.9063 - val_recall_function: 0.8864\n",
            "Treino completo no tempo:  1:13:07.566539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4ujHnbsFPyu"
      },
      "source": [
        "def grafico(nome_modelo):\n",
        "\n",
        "    plt.plot(nome_modelo.history['accuracy'])\n",
        "    plt.plot(nome_modelo.history['val_accuracy'])\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Val'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(nome_modelo.history['loss'])\n",
        "    plt.plot(nome_modelo.history['val_loss'])\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Val'], loc='upper right')\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(nome_modelo.history['f1_m'])\n",
        "    plt.plot(nome_modelo.history['val_f1_m'])\n",
        "    plt.title('Model F1_Score')\n",
        "    plt.ylabel('F1_Score')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Val'], loc='upper right')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmUkPEhcFVgr"
      },
      "source": [
        "grafico(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84DT-A_sF-kw"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "def confusion_matrix(test_data_generator, model):\n",
        "  test_data_generator.reset()\n",
        "  predictions = model.predict(test_data_generator, steps=teste_set.samples)\n",
        "  # Get most likely class\n",
        "  predicted_classes = np.argmax(predictions, axis=1)\n",
        "  true_classes = test_data_generator.classes\n",
        "  class_labels = list(test_data_generator.class_indices.keys())\n",
        "  print(class_labels)  \n",
        "\n",
        "  report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "  cm = metrics.confusion_matrix(true_classes, predicted_classes)\n",
        "  print(report)\n",
        "  plot_confusion_matrix(cm, class_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJxXuDBUGE9D"
      },
      "source": [
        "confusion_matrix(teste_set, model_novo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ppYsMeBX1Sz"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "\n",
        "def plot_roc(predictions,gold,model_name):\n",
        "  pred_ravel = predictions.ravel()\n",
        "  fpr, tpr, thresholds = roc_curve(gold, predictions)\n",
        "  _auc = auc(fpr, tpr)\n",
        "  plt.figure(1)\n",
        "  plt.plot([0, 1], [0, 1], 'k--')\n",
        "  plt.plot(fpr, tpr, label=model_name +' (area = {:.3f})'.format(_auc))\n",
        " # plt.plot(fpr_rf, tpr_rf, label='RF (area = {:.3f})'.format(auc_rf))\n",
        "  plt.xlabel('False positive rate')\n",
        "  plt.ylabel('True positive rate')\n",
        "  plt.title('ROC curve')\n",
        "  plt.legend(loc='best')\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZizMuGU-FSr"
      },
      "source": [
        "n_class = 12\n",
        "\n",
        "for i in range(n_class):    \n",
        "    fpr[i], tpr[i], thresh[i] = roc_curve(teste_datagen, pred_prob[:,i], pos_label=i)\n",
        "    \n",
        "# plotting    \n",
        "plt.plot(fpr[0], tpr[0], linestyle='--',color='orange', label='Class 0 vs Rest')\n",
        "plt.plot(fpr[1], tpr[1], linestyle='--',color='green', label='Class 1 vs Rest')\n",
        "plt.plot(fpr[2], tpr[2], linestyle='--',color='blue', label='Class 2 vs Rest')\n",
        "plt.title('Multiclass ROC curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive rate')\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}